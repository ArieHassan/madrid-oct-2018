{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/arie/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/arie/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/arie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(s):\n",
    "    \"\"\"\n",
    "    Cleans up numbers, URLs, and special characters from a string.\n",
    "    Args:\n",
    "        s: The string to be cleaned up.\n",
    "    Returns:\n",
    "        A string that has been cleaned up.\n",
    "    \"\"\"\n",
    "    comp = re.compile('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.]+|[\\W\\d]')\n",
    "    return (re.sub(comp,\" \",s)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    \"\"\"\n",
    "    Tokenize a string.\n",
    "    Args:\n",
    "        s: String to be tokenized.\n",
    "    Returns:\n",
    "        A list of words as the result of tokenization.\n",
    "    \"\"\"\n",
    "    return word_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_lemmatize(l):\n",
    "    \"\"\"\n",
    "    Perform stemming and lemmatization on a list of words.\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "    Returns:\n",
    "        A list of strings after being stemmed and lemmatized.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(l):\n",
    "    \"\"\"\n",
    "    Remove English stopwords from a list of strings.\n",
    "\n",
    "    Args:\n",
    "        l: A list of strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings after stop words are removed.\n",
    "    \"\"\"\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    filtered = [word for word in l if word not in stopWords and len(word)>1]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sentiment140.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    779\n",
       "0    721\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = negative, 4 = positive\n",
    "df.head()\n",
    "df = df.sample(1500)\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_processed\"] = df[\"text\"].apply(clean_up)\n",
    "df[\"text_processed\"] = df[\"text_processed\"].apply(tokenize)\n",
    "df[\"text_processed\"] = df[\"text_processed\"].apply(stem_and_lemmatize)\n",
    "df[\"text_processed\"]=df[\"text_processed\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df[\"text_processed\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word2 for word in words for word2 in word]\n",
    "all_words2 = nltk.FreqDist(all_words)\n",
    "word_features = list(all_words2.keys())[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.0.1/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_util = df[[\"id\",\"target\",\"text_processed\"]]\n",
    "df_util[\"target\"]= df_util[\"target\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = df_util[\"text_processed\"].tolist()\n",
    "target = df_util[\"target\"].tolist()\n",
    "documents = list(zip(palabras,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    word = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_set = [(find_features(doc),target) for (doc,target) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'greggrunberg': False,\n",
       "  'deaf': False,\n",
       "  'wait': False,\n",
       "  'star': False,\n",
       "  'trek': False,\n",
       "  'dvd': False,\n",
       "  'arrive': False,\n",
       "  'later': False,\n",
       "  'wizzzle': False,\n",
       "  'im': False,\n",
       "  'bored': False,\n",
       "  'dunno': False,\n",
       "  'nose': False,\n",
       "  'stuffed': False,\n",
       "  'want': False,\n",
       "  'hate': False,\n",
       "  'wasting': False,\n",
       "  'gorgeous': False,\n",
       "  'day': False,\n",
       "  'sick': False,\n",
       "  'season': False,\n",
       "  'office': False,\n",
       "  'funny': False,\n",
       "  'jim': False,\n",
       "  'mess': False,\n",
       "  'dwight': False,\n",
       "  'hot': False,\n",
       "  'self': False,\n",
       "  'oral': False,\n",
       "  'surgen': False,\n",
       "  'found': False,\n",
       "  'blood': False,\n",
       "  'clot': False,\n",
       "  'poked': False,\n",
       "  'mouth': False,\n",
       "  'hurt': False,\n",
       "  'man': False,\n",
       "  'cried': False,\n",
       "  'antibotics': False,\n",
       "  'made': False,\n",
       "  'peanut': False,\n",
       "  'butter': False,\n",
       "  'buckwheat': False,\n",
       "  'pancake': False,\n",
       "  'amp': False,\n",
       "  'strawberry': False,\n",
       "  'blueberry': False,\n",
       "  'granola': False,\n",
       "  'vanilla': False,\n",
       "  'yogurt': False,\n",
       "  'parfait': False,\n",
       "  'breakfast': False,\n",
       "  'yum': False,\n",
       "  'gagging': False,\n",
       "  'love': False,\n",
       "  'take': False,\n",
       "  'phone': False,\n",
       "  'hey': False,\n",
       "  'tweet': False,\n",
       "  'good': False,\n",
       "  'nite': False,\n",
       "  'last': False,\n",
       "  'go': False,\n",
       "  'maybe': False,\n",
       "  'little': False,\n",
       "  'jack_of_clubs': False,\n",
       "  'la': False,\n",
       "  'roux': False,\n",
       "  'better': False,\n",
       "  'sound': False,\n",
       "  'summer': False,\n",
       "  'going': False,\n",
       "  'beach': False,\n",
       "  'george': False,\n",
       "  'working': False,\n",
       "  'hippiechick': False,\n",
       "  'truly': False,\n",
       "  'delightful': False,\n",
       "  'wa': False,\n",
       "  'sweet': False,\n",
       "  'sour': False,\n",
       "  'egg': False,\n",
       "  'roll': False,\n",
       "  'seem': False,\n",
       "  'pc': False,\n",
       "  'rettkearbey': False,\n",
       "  'bro': False,\n",
       "  'need': False,\n",
       "  'watch': False,\n",
       "  'ufc': False,\n",
       "  'come': False,\n",
       "  'win': False,\n",
       "  'money': False,\n",
       "  'poker': False,\n",
       "  'awhile': False,\n",
       "  'since': False,\n",
       "  'tweeted': False,\n",
       "  'myweakness': False,\n",
       "  'blocknurse': False,\n",
       "  'awwww': False,\n",
       "  'thanks': False,\n",
       "  'donna': False,\n",
       "  'series': False,\n",
       "  'digicam': False,\n",
       "  'still': False,\n",
       "  'one': False,\n",
       "  'lux': False,\n",
       "  'leowolfe': False,\n",
       "  'cant': False,\n",
       "  'refuse': False,\n",
       "  'play': False,\n",
       "  'common': False,\n",
       "  'knowledge': False,\n",
       "  'rule': False,\n",
       "  'quot': False,\n",
       "  'always': False,\n",
       "  'playing': False,\n",
       "  'game': False,\n",
       "  'lynsey_xo': False,\n",
       "  'got': False,\n",
       "  'pink': False,\n",
       "  'bikini': False,\n",
       "  'like': False,\n",
       "  'twin': False,\n",
       "  'listening': False,\n",
       "  'music': False,\n",
       "  'craigeryowens': False,\n",
       "  'know': False,\n",
       "  'album': False,\n",
       "  'listen': False,\n",
       "  'oceana': False,\n",
       "  'unfortnetly': False,\n",
       "  'announced': False,\n",
       "  'breakup': False,\n",
       "  'ubd': False,\n",
       "  'moneymaker': False,\n",
       "  'theme': False,\n",
       "  'feerburner': False,\n",
       "  'widget': False,\n",
       "  'ha': False,\n",
       "  'mail': False,\n",
       "  'publicized': False,\n",
       "  'sure': False,\n",
       "  'wrong': False,\n",
       "  'watching': False,\n",
       "  'drag': False,\n",
       "  'hell': False,\n",
       "  'anyone': False,\n",
       "  'wan': False,\n",
       "  'na': False,\n",
       "  'meh': False,\n",
       "  'jackjewers': False,\n",
       "  'hah': False,\n",
       "  'notice': False,\n",
       "  'davis': False,\n",
       "  'particularly': False,\n",
       "  'loses': False,\n",
       "  'discussion': False,\n",
       "  'duck': False,\n",
       "  'squeeze': False,\n",
       "  'small': False,\n",
       "  'opening': False,\n",
       "  'ahhhhh': False,\n",
       "  'ear': False,\n",
       "  'wont': False,\n",
       "  'stop': False,\n",
       "  'trying': False,\n",
       "  'write': False,\n",
       "  'paper': False,\n",
       "  'concentrate': False,\n",
       "  'walking': False,\n",
       "  'home': False,\n",
       "  'yayyyy': False,\n",
       "  'positive': False,\n",
       "  'case': False,\n",
       "  'swine': False,\n",
       "  'flu': False,\n",
       "  'around': False,\n",
       "  'soo': False,\n",
       "  'much': False,\n",
       "  'homework': False,\n",
       "  'weekend': False,\n",
       "  'though': False,\n",
       "  'dc': False,\n",
       "  'shoe': False,\n",
       "  'body': False,\n",
       "  'awnnnnnnnnnnnnnn': False,\n",
       "  'mtmtmtmtmt': False,\n",
       "  'felixxxxxxx': False,\n",
       "  'missknight': False,\n",
       "  'morning': False,\n",
       "  'cornbread': False,\n",
       "  'wssup': False,\n",
       "  'beautiful': False,\n",
       "  'ya': False,\n",
       "  'braz': False,\n",
       "  'flexible': False,\n",
       "  'course': False,\n",
       "  'potstickers': False,\n",
       "  'bjs': False,\n",
       "  'really': False,\n",
       "  'away': False,\n",
       "  'fast': False,\n",
       "  'omg': False,\n",
       "  'clicked': False,\n",
       "  'thing': False,\n",
       "  'yesterday': False,\n",
       "  'became': False,\n",
       "  'robot': False,\n",
       "  'sorry': False,\n",
       "  'people': False,\n",
       "  'coolia': False,\n",
       "  'awesome': False,\n",
       "  'catmagellan': False,\n",
       "  'welcome': False,\n",
       "  'que': False,\n",
       "  'tema': False,\n",
       "  'teoria': False,\n",
       "  'bem': False,\n",
       "  'merecem': False,\n",
       "  'twit': False,\n",
       "  'miss': False,\n",
       "  'church': False,\n",
       "  'today': False,\n",
       "  'seaquest': False,\n",
       "  'jus': False,\n",
       "  'bday': False,\n",
       "  'party': False,\n",
       "  'nga': False,\n",
       "  'tonight': False,\n",
       "  'dad': False,\n",
       "  'even': False,\n",
       "  'drop': False,\n",
       "  'back': False,\n",
       "  'rub': False,\n",
       "  'dead': False,\n",
       "  'vacay': False,\n",
       "  'suzanneyankovic': False,\n",
       "  'aww': False,\n",
       "  'ok': False,\n",
       "  'harm': False,\n",
       "  'done': False,\n",
       "  'shame': False,\n",
       "  'waste': False,\n",
       "  'hope': False,\n",
       "  'rest': False,\n",
       "  'evening': False,\n",
       "  'zorro': False,\n",
       "  'fruit': False,\n",
       "  'grocery': False,\n",
       "  'shopping': False,\n",
       "  'awful': False,\n",
       "  'full': False,\n",
       "  'study': False,\n",
       "  'wonder': False,\n",
       "  'hungry': False,\n",
       "  'finished': False,\n",
       "  'eating': False,\n",
       "  'rain': False,\n",
       "  'perze': False,\n",
       "  'gut': False,\n",
       "  'feel': False,\n",
       "  'say': False,\n",
       "  'gon': False,\n",
       "  'boy': False,\n",
       "  'ababa': False,\n",
       "  'profile': False,\n",
       "  'pic': False,\n",
       "  'doe': False,\n",
       "  'show': False,\n",
       "  'new': False,\n",
       "  'prior': False,\n",
       "  'haircut': False,\n",
       "  'disasterous': False,\n",
       "  'proportion': False,\n",
       "  'ryandanieltft': False,\n",
       "  'complain': False,\n",
       "  'raining': False,\n",
       "  'see': False,\n",
       "  'soon': False,\n",
       "  'buddy': False,\n",
       "  'coffee': False,\n",
       "  'newspaper': False,\n",
       "  'nothing': False,\n",
       "  'get': False,\n",
       "  'make': False,\n",
       "  'candy': False,\n",
       "  'bowling': False,\n",
       "  'tonite': False,\n",
       "  'fuck': False,\n",
       "  'dementedriku': False,\n",
       "  'yup': False,\n",
       "  'imagine': False,\n",
       "  'gabby': False,\n",
       "  'world': False,\n",
       "  'vision': False,\n",
       "  'conference': False,\n",
       "  'todaaayy': False,\n",
       "  'lt': False,\n",
       "  'elaineq': False,\n",
       "  'slowly': False,\n",
       "  'recovering': False,\n",
       "  'pneumonia': False,\n",
       "  'week': False,\n",
       "  'old': False,\n",
       "  'ugh': False,\n",
       "  'sending': False,\n",
       "  'lot': False,\n",
       "  'well': False,\n",
       "  'vibe': False,\n",
       "  'visa': False,\n",
       "  'process': False,\n",
       "  'saudi': False,\n",
       "  'messing': False,\n",
       "  'effat': False,\n",
       "  'jeddah': False,\n",
       "  'yet': False,\n",
       "  'finger': False,\n",
       "  'crossed': False,\n",
       "  'freaking': False,\n",
       "  'broiled': False,\n",
       "  'tilapia': False,\n",
       "  'lump': False,\n",
       "  'crabmeat': False,\n",
       "  'exquisite': False,\n",
       "  'think': False,\n",
       "  'fair': False,\n",
       "  'husband': False,\n",
       "  'nice': False,\n",
       "  'inpromptu': False,\n",
       "  'sp': False,\n",
       "  'pub': False,\n",
       "  'lunch': False,\n",
       "  'family': False,\n",
       "  'stuck': False,\n",
       "  'work': False,\n",
       "  'hazey': False,\n",
       "  'heading': False,\n",
       "  'tomorrow': False,\n",
       "  'sexxyblackinese': False,\n",
       "  'ohh': False,\n",
       "  'yeaaa': False,\n",
       "  'cause': False,\n",
       "  'pay': False,\n",
       "  'mine': False,\n",
       "  'lol': False,\n",
       "  'awwh': False,\n",
       "  'effin': False,\n",
       "  'locked': False,\n",
       "  'key': False,\n",
       "  'house': False,\n",
       "  'outside': False,\n",
       "  'wtf': False,\n",
       "  'supposed': False,\n",
       "  'pump': False,\n",
       "  'degree': False,\n",
       "  'damn': False,\n",
       "  'exam': False,\n",
       "  'mean': False,\n",
       "  'revision': False,\n",
       "  'whole': False,\n",
       "  'year': False,\n",
       "  'jfreake': False,\n",
       "  'guy': False,\n",
       "  'try': False,\n",
       "  'glass': False,\n",
       "  'nathanschultze': False,\n",
       "  'oh': False,\n",
       "  'kid': False,\n",
       "  'twitter': False,\n",
       "  'chiggyx': False,\n",
       "  'spend': False,\n",
       "  'time': False,\n",
       "  'kevirus': False,\n",
       "  'loled': False,\n",
       "  'everything': False,\n",
       "  'involving': False,\n",
       "  'calculator': False,\n",
       "  'settling': False,\n",
       "  'hopefully': False,\n",
       "  'night': False,\n",
       "  'sleep': False,\n",
       "  'also': False,\n",
       "  'santa': False,\n",
       "  'cruz': False,\n",
       "  'cherrymafia': False,\n",
       "  'would': False,\n",
       "  'sooo': False,\n",
       "  'rome': False,\n",
       "  'big': False,\n",
       "  'dream': False,\n",
       "  'boyfriend': False,\n",
       "  'mad': False,\n",
       "  'kirstiekalamity': False,\n",
       "  'adam': False,\n",
       "  'sandler': False,\n",
       "  'movie': False,\n",
       "  'juanskii': False,\n",
       "  'said': False,\n",
       "  'universe': False,\n",
       "  'mostly': False,\n",
       "  'meant': False,\n",
       "  'exhausted': False,\n",
       "  'wake': False,\n",
       "  'rosiekonc': False,\n",
       "  'woke': False,\n",
       "  'already': False,\n",
       "  'blame': False,\n",
       "  'finally': False,\n",
       "  'washing': False,\n",
       "  'ungodly': False,\n",
       "  'amound': False,\n",
       "  'quite': False,\n",
       "  'sad': False,\n",
       "  'cry': False,\n",
       "  'comedian': False,\n",
       "  'pity': False,\n",
       "  'whoooo': False,\n",
       "  'slow': False,\n",
       "  'pretty': False,\n",
       "  'excitement': False,\n",
       "  'probably': False,\n",
       "  'boring': False,\n",
       "  'paulandstorm': False,\n",
       "  'paul': False,\n",
       "  'xkcd': False,\n",
       "  'written': False,\n",
       "  'mind': False,\n",
       "  'mark': False,\n",
       "  'math': False,\n",
       "  'reasonable': False,\n",
       "  'cash': False,\n",
       "  'google': False,\n",
       "  'adsense': False,\n",
       "  'paypal': False,\n",
       "  'yungceo': False,\n",
       "  'nuthin': False,\n",
       "  'muchhh': False,\n",
       "  'chillin': False,\n",
       "  'doin': False,\n",
       "  'definatalie': False,\n",
       "  'wow': False,\n",
       "  'bked': False,\n",
       "  'mile': False,\n",
       "  'guess': False,\n",
       "  'triumph': False,\n",
       "  'achy': False,\n",
       "  'head': False,\n",
       "  'help': False,\n",
       "  'making': False,\n",
       "  'birthday': False,\n",
       "  'coming': False,\n",
       "  'androidtomato': False,\n",
       "  'hello': False,\n",
       "  'girl': False,\n",
       "  'rafa': False,\n",
       "  'convincingly': False,\n",
       "  'end': False,\n",
       "  'nearly': False,\n",
       "  'thematic': False,\n",
       "  'thank': False,\n",
       "  'god': False,\n",
       "  'me_piglet': False,\n",
       "  'let': False,\n",
       "  'discus': False,\n",
       "  'via': False,\n",
       "  'dm': False,\n",
       "  'spoiler': False,\n",
       "  'smth': False,\n",
       "  'accidentally': False,\n",
       "  'alright': False,\n",
       "  'taylorswift': False,\n",
       "  'heya': False,\n",
       "  'could': False,\n",
       "  'check': False,\n",
       "  'amazing': False,\n",
       "  'find': False,\n",
       "  'xxx': False,\n",
       "  'aw': False,\n",
       "  'gee': False,\n",
       "  'odotallen': False,\n",
       "  'seeing': False,\n",
       "  'cr': False,\n",
       "  'booth': False,\n",
       "  'track': False,\n",
       "  'troubled': False,\n",
       "  'easter': False,\n",
       "  'greek': False,\n",
       "  'orthodox': False,\n",
       "  'xristos': False,\n",
       "  'anesti': False,\n",
       "  'incidentally': False,\n",
       "  'thought': False,\n",
       "  'bbq': False,\n",
       "  'pm': False,\n",
       "  'mrskutcher': False,\n",
       "  'look': False,\n",
       "  'stunning': False,\n",
       "  'hair': False,\n",
       "  'colour': False},\n",
       " 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_set[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = features_set[:1400]\n",
    "testing_set = features_set[1400:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "nltk.classify.accuracy(classifier,testing_set)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92287</th>\n",
       "      <td>1759964968</td>\n",
       "      <td>0</td>\n",
       "      <td>[greggrunberg, deaf, wait, star, trek, dvd, ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700636</th>\n",
       "      <td>2254825925</td>\n",
       "      <td>0</td>\n",
       "      <td>[wizzzle, im, bored, dunno]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318495</th>\n",
       "      <td>2002833903</td>\n",
       "      <td>0</td>\n",
       "      <td>[nose, stuffed, want, hate, wasting, gorgeous,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771810</th>\n",
       "      <td>2302515240</td>\n",
       "      <td>0</td>\n",
       "      <td>[season, office, funny, jim, office, mess, dwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565883</th>\n",
       "      <td>2206657060</td>\n",
       "      <td>0</td>\n",
       "      <td>[oral, surgen, found, blood, clot, poked, mout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959636</th>\n",
       "      <td>1826102402</td>\n",
       "      <td>4</td>\n",
       "      <td>[made, peanut, butter, buckwheat, pancake, amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481793</th>\n",
       "      <td>2179777105</td>\n",
       "      <td>0</td>\n",
       "      <td>[gagging, love, take, phone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484500</th>\n",
       "      <td>2067683800</td>\n",
       "      <td>4</td>\n",
       "      <td>[hey, hey, tweet, good, nite, last, go, maybe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235031</th>\n",
       "      <td>1979704809</td>\n",
       "      <td>0</td>\n",
       "      <td>[jack_of_clubs, la, roux, better, sound, summe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810220</th>\n",
       "      <td>1469703214</td>\n",
       "      <td>4</td>\n",
       "      <td>[sound, george, working, good]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id target                                     text_processed\n",
       "92287    1759964968      0  [greggrunberg, deaf, wait, star, trek, dvd, ar...\n",
       "700636   2254825925      0                        [wizzzle, im, bored, dunno]\n",
       "318495   2002833903      0  [nose, stuffed, want, hate, wasting, gorgeous,...\n",
       "771810   2302515240      0  [season, office, funny, jim, office, mess, dwi...\n",
       "565883   2206657060      0  [oral, surgen, found, blood, clot, poked, mout...\n",
       "959636   1826102402      4  [made, peanut, butter, buckwheat, pancake, amp...\n",
       "481793   2179777105      0                       [gagging, love, take, phone]\n",
       "1484500  2067683800      4  [hey, hey, tweet, good, nite, last, go, maybe,...\n",
       "235031   1979704809      0  [jack_of_clubs, la, roux, better, sound, summe...\n",
       "810220   1469703214      4                     [sound, george, working, good]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
